{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: Face Recognition using OpenCV and Python\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Defining paths\n",
    "\n",
    "SRC_PATH = os.getcwd()\n",
    "ASSETS_PATH = os.path.join(SRC_PATH, 'assets')\n",
    "IMAGES_PATH = os.path.join(ASSETS_PATH, 'Images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and preprocessing the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import Mat\n",
    "\n",
    "def show_image(image_path:str = None, cv2_image:Mat = None, title:str=\"Image\") -> None:\n",
    "    \"\"\"Shows an image in a window with cv2. And waits for a key to be pressed to close the window.\n",
    "    The path to the image or the image object must be provided.\n",
    "\n",
    "    Args:\n",
    "        image_path (str, optional): Path to the image to show. Defaults to None.\n",
    "        cv2_image (Mat, optional): Image object to show. Defaults to None.\n",
    "        title (str, optional): Title of the window containing the shown image. Defaults to \"Image\".\n",
    "    \"\"\"\n",
    "    if image_path is None and cv2_image is None:\n",
    "        raise Exception(\"No image to show\")\n",
    "    \n",
    "    if image_path is not None:\n",
    "        image_to_show = cv2.imread(image_path)\n",
    "    else: \n",
    "        image_to_show = cv2_image\n",
    "    \n",
    "    cv2.imshow(title, image_to_show)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyWindow(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 1920, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people_image = os.path.join(IMAGES_PATH, \"people1.jpg\")\n",
    "image = cv2.imread(people_image)\n",
    "image.shape # (height, width, channels), channels are BGR, has three channels. Tougher to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(image_path=people_image, title=\"People Image\") # Shows the image in a window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.resize(image, (800, 600)) # Resizes the image to 800x600 pixels.\n",
    "show_image(cv2_image=image, title=\"Resized Image\")\n",
    "image.shape # (600, 800, 3). Still has three channels. Must be converted to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 800, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Converts the image to grayscale.\n",
    "show_image(cv2_image=gray_image, title=\"Gray Image\")\n",
    "image.shape # (600, 800). Now has only one channel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected:  5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[386, 232,  74,  74],\n",
       "       [ 90, 238,  69,  69],\n",
       "       [113, 122,  56,  56],\n",
       "       [475, 122,  60,  60],\n",
       "       [678,  74,  65,  65]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facial_detector_path = os.path.join(ASSETS_PATH, \"Cascades\", \"haarcascade_frontalface_default.xml\")\n",
    "facial_detector = cv2.CascadeClassifier(facial_detector_path)\n",
    "detections = facial_detector.detectMultiScale(gray_image, scaleFactor=1.09) # Detects faces in the image.\n",
    "print(\"Number of faces detected: \", len(detections))\n",
    "detections # Array of tuples. Each tuple contains the coordinates of the top left corner of the face \n",
    "           # and the width and height of the face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangles_in_image(image:Mat, rectangles:list[tuple], color:tuple=(0, 255, 0), thickness:int = 2) -> None:\n",
    "    \"\"\"Draws green rectangles in an image.\n",
    "\n",
    "    Args:\n",
    "        image (Mat): Image to draw the rectangles in.\n",
    "        rectangles (list): List of tuples. Each tuple contains the coordinates of the top left corner of the rectangle \n",
    "                           and the width and height of the rectangle.\n",
    "        color (tuple, optional): Color of the rectangles. Defaults to (0, 255, 0), green.\n",
    "        thickness (int, optional): Thickness of the rectangles. Defaults to 2.\n",
    "    \"\"\"\n",
    "    for (x, y, w, h) in rectangles:\n",
    "        cv2.rectangle(image, (x, y), (x+w, y+h), color, thickness) # (x, y) is the top left corner of the rectangle.\n",
    "                                                                 # (x+w, y+h) is the bottom right corner of the rectangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_rectangles_in_image(image, detections) # Draws detections in the image as green rectangles.\n",
    "show_image(cv2_image=image, title=\"Detections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting faces in a second image\n",
    "\n",
    "# Loading and preparing the second image\n",
    "image_2_path = os.path.join(IMAGES_PATH, \"people2.jpg\")\n",
    "image_2 = cv2.imread(image_2_path)\n",
    "gray_image_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detecting faces in the second image\n",
    "detections_2 = facial_detector.detectMultiScale(gray_image_2, scaleFactor=1.2, minNeighbors=3,\n",
    "                                             minSize=(32,32), maxSize=(100,100)) # Even through ajusting the parameters, the F1 score isn't 100%.\n",
    "\n",
    "# Drawing the detections in the second image\n",
    "draw_rectangles_in_image(image_2, detections_2)\n",
    "\n",
    "# Showing the second image with the detections\n",
    "show_image(cv2_image=image_2, title=\"Detections 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eye detection in first image, which had to be resized, because the eyes are smaller than the faces.\n",
    "image = cv2.resize(image, (1920, 1280))\n",
    "gray_image = cv2.resize(gray_image, (1920, 1280))\n",
    "\n",
    "# Detecting eyes in the first image\n",
    "eye_detector_path = os.path.join(ASSETS_PATH, \"Cascades\", \"haarcascade_eye.xml\")\n",
    "eye_detector = cv2.CascadeClassifier(eye_detector_path)\n",
    "eye_detections = eye_detector.detectMultiScale(gray_image, scaleFactor=1.24, minNeighbors=10, maxSize=(70,70))\n",
    "\n",
    "# Drawing the eye detections in the first image\n",
    "draw_rectangles_in_image(image, eye_detections, color=(255, 0, 0))\n",
    "\n",
    "# Showing the first image with the eye detections\n",
    "show_image(cv2_image=image, title=\"Eye Detections\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e5b5b920195072d4a4eec1d5ff9e5f87252d2725e2a57da6939cd4fcd91d4cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
